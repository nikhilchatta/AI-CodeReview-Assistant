name: AI Code Review Gate

# Reusable workflow â€” called by ai-review.yml in any target repository.
# Uses Python's http.client for all backend calls (avoids curl/nginx body issues).

on:
  workflow_call:
    inputs:
      max_files:
        description: Maximum number of changed files to send for review
        type: number
        default: 20
      file_extensions:
        description: Comma-separated file extensions to include (e.g. .py,.ts,.scala)
        type: string
        default: .py,.ts,.tsx,.js,.jsx,.scala,.sql,.tf
      timeout_minutes:
        description: Maximum minutes the review job is allowed to run
        type: number
        default: 30
    secrets:
      AI_AGENT_API_URL:
        required: true
        description: Base URL of the AI agent backend (e.g. http://1.2.3.4)
      AI_AGENT_API_KEY:
        required: true
        description: API key for authenticating with the AI agent backend

jobs:
  ai-code-review-gate:
    name: AI Code Review Gate
    runs-on: ubuntu-latest
    timeout-minutes: ${{ inputs.timeout_minutes }}
    permissions:
      contents: read
      pull-requests: write

    steps:

      # â”€â”€ Step 1: Verify backend is reachable â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Verify backend connectivity
        env:
          API_URL: ${{ secrets.AI_AGENT_API_URL }}
          API_KEY: ${{ secrets.AI_AGENT_API_KEY }}
        run: |
          echo "Checking ${API_URL}/api/health ..."
          HTTP_STATUS=$(curl -s --max-time 15 \
            -o /tmp/health.json -w "%{http_code}" \
            -H "x-api-key: ${API_KEY}" \
            "${API_URL}/api/health")
          echo "Health status: ${HTTP_STATUS}"
          if [ "$HTTP_STATUS" != "200" ]; then
            echo "::error::Backend not reachable (HTTP ${HTTP_STATUS}). Check AI_AGENT_API_URL secret."
            cat /tmp/health.json 2>/dev/null || true
            exit 1
          fi
          cat /tmp/health.json

      # â”€â”€ Step 2: Checkout PR code with full history for diff â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Checkout PR code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ github.event.pull_request.head.sha }}

      # â”€â”€ Step 3: Compute changed files from PR diff â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Compute changed files
        id: diff
        env:
          BASE_REF:    ${{ github.base_ref }}
          PR_HEAD_SHA: ${{ github.event.pull_request.head.sha }}
          MAX_FILES:   ${{ inputs.max_files }}
          EXTENSIONS:  ${{ inputs.file_extensions }}
        run: |
          git fetch origin "${BASE_REF}"
          DIFF_HEAD="${PR_HEAD_SHA:-HEAD}"
          echo "Diff: origin/${BASE_REF}...${DIFF_HEAD}"

          PATTERNS=$(echo "$EXTENSIONS" | tr ',' '\n' | sed 's/^\./\*./g' | tr '\n' ' ')
          FILES=$(git diff --name-only --diff-filter=ACMRT \
            "origin/${BASE_REF}...${DIFF_HEAD}" \
            -- $PATTERNS 2>/dev/null | head -n "$MAX_FILES")

          if [ -z "$FILES" ]; then
            echo "no_files=true" >> "$GITHUB_OUTPUT"
            echo "No matching files changed â€” skipping AI review."
          else
            echo "no_files=false" >> "$GITHUB_OUTPUT"
            FILE_COUNT=$(echo "$FILES" | wc -l | tr -d ' ')
            echo "file_count=${FILE_COUNT}" >> "$GITHUB_OUTPUT"
            echo "$FILES" > /tmp/changed_files.txt
            echo "Files to review (${FILE_COUNT}):"
            cat /tmp/changed_files.txt
          fi

      # â”€â”€ Step 4: Skip when no reviewable files â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: Skip â€” no reviewable files changed
        if: steps.diff.outputs.no_files == 'true'
        run: |
          echo "No files matching [${{ inputs.file_extensions }}] were changed."
          echo "AI code review gate skipped â€” nothing to review."

      # â”€â”€ Step 5: AI review â†’ PR comment â†’ record metrics â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      #
      # Uses Python http.client directly â€” no curl â€” so Content-Length is always
      # set correctly and no nginx proxy_request_buffering issues can drop the body.
      - name: AI review, post comment, record metrics
        id: review
        if: steps.diff.outputs.no_files == 'false'
        env:
          API_URL:    ${{ secrets.AI_AGENT_API_URL }}
          API_KEY:    ${{ secrets.AI_AGENT_API_KEY }}
          GH_TOKEN:   ${{ github.token }}
          PR_NUMBER:  ${{ github.event.pull_request.number }}
          REPO:       ${{ github.repository }}
          HEAD_REF:   ${{ github.head_ref }}
          BASE_REF:   ${{ github.base_ref }}
          COMMIT_SHA: ${{ github.sha }}
          ACTOR:      ${{ github.actor }}
          RUN_ID:     ${{ github.run_id }}
        run: |
          python3 << 'PYEOF'
          import json, os, sys, time, ssl
          import http.client, urllib.parse

          # â”€â”€ helper: POST JSON via Python http.client (no curl) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          def api_post(base_url, path, payload, extra_headers=None):
              parsed = urllib.parse.urlparse(base_url)
              host   = parsed.hostname
              port   = parsed.port or (443 if parsed.scheme == 'https' else 80)
              body   = json.dumps(payload, ensure_ascii=False).encode('utf-8')
              hdrs   = {
                  'Content-Type':   'application/json; charset=utf-8',
                  'Content-Length': str(len(body)),
                  'Connection':     'close',
              }
              if extra_headers:
                  hdrs.update(extra_headers)
              try:
                  if parsed.scheme == 'https':
                      conn = http.client.HTTPSConnection(
                          host, port, timeout=300,
                          context=ssl.create_default_context())
                  else:
                      conn = http.client.HTTPConnection(host, port, timeout=300)
                  conn.request('POST', path, body=body, headers=hdrs)
                  resp = conn.getresponse()
                  st   = resp.status
                  raw  = resp.read()
                  conn.close()
              except Exception as e:
                  raise RuntimeError(f'HTTP request to {host}{path} failed: {e}')
              try:
                  return st, json.loads(raw)
              except Exception:
                  return st, {'_raw': raw.decode('utf-8', errors='replace')}

          # â”€â”€ config from environment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          API_URL  = os.environ['API_URL'].strip().rstrip('/')
          API_KEY  = os.environ['API_KEY'].strip()
          GH_TOKEN = os.environ['GH_TOKEN'].strip()
          REPO     = os.environ['REPO']
          RUN_ID   = os.environ['RUN_ID']
          PR_NUM   = int(os.environ.get('PR_NUMBER') or 0)
          ACTOR    = os.environ.get('ACTOR', '')
          BRANCH   = os.environ.get('HEAD_REF', '')
          BASE_BR  = os.environ.get('BASE_REF', '')
          SHA      = os.environ.get('COMMIT_SHA', '')
          PROJECT  = REPO.split('/')[-1]
          WS       = os.environ.get('GITHUB_WORKSPACE', '')
          GH_OUT   = os.environ.get('GITHUB_OUTPUT', '/dev/null')

          EXT_LANG = {
              '.py':     'python',
              '.pyspark':'pyspark',
              '.ts':     'typescript',
              '.tsx':    'typescript',
              '.js':     'javascript',
              '.jsx':    'javascript',
              '.scala':  'scala',
              '.sql':    'sql',
              '.tf':     'terraform',
          }

          # â”€â”€ build files array from diff output â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          files = []
          with open('/tmp/changed_files.txt') as fh:
              paths = [l.strip() for l in fh if l.strip()]

          for fpath in paths:
              full = os.path.join(WS, fpath) if WS else fpath
              if not os.path.isfile(full):
                  print(f'[skip] not found: {fpath}', file=sys.stderr)
                  continue
              ext  = os.path.splitext(fpath)[1].lower()
              lang = EXT_LANG.get(ext)
              if not lang:
                  continue
              try:
                  with open(full, 'r', encoding='utf-8', errors='replace') as f:
                      content = f.read()
                  if len(content) > 102400:
                      content = content[:102400]
                      print(f'[warn] truncated {fpath} to 100 KB', file=sys.stderr)
                  files.append({'path': fpath, 'content': content, 'language': lang})
              except Exception as e:
                  print(f'[warn] cannot read {fpath}: {e}', file=sys.stderr)

          if not files:
              print('No readable files after filtering â€” skipping.', file=sys.stderr)
              with open(GH_OUT, 'a') as gf:
                  gf.write('gate_status=pass\ntotal_issues=0\ncritical_count=0\n')
              sys.exit(0)

          print(f'[review] Submitting {len(files)} file(s) to {API_URL}/api/review/pr ...', file=sys.stderr)

          review_payload = {
              'files':         files,
              'analysis_type': 'review',
              'metadata': {
                  'repository':      REPO,
                  'pr_number':       PR_NUM,
                  'branch':          BRANCH,
                  'base_branch':     BASE_BR,
                  'commit_sha':      SHA,
                  'actor':           ACTOR,
                  'workflow_run_id': RUN_ID,
                  'project_id':      PROJECT,
              },
          }

          # â”€â”€ call /api/review/pr via Python http.client â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          t0 = time.time()
          try:
              http_st, review = api_post(
                  API_URL, '/api/review/pr', review_payload,
                  extra_headers={'x-api-key': API_KEY})
          except Exception as e:
              print(f'::error::Review API call failed: {e}', file=sys.stderr)
              with open(GH_OUT, 'a') as gf:
                  gf.write('gate_status=fail\ntotal_issues=0\ncritical_count=0\n')
              sys.exit(1)

          elapsed_ms = int((time.time() - t0) * 1000)

          if http_st != 200:
              print(f'::error::Review API returned HTTP {http_st}: {review}', file=sys.stderr)
              with open(GH_OUT, 'a') as gf:
                  gf.write('gate_status=fail\ntotal_issues=0\ncritical_count=0\n')
              sys.exit(1)

          gate         = review.get('gate_status', 'pass')
          run_id_full  = review.get('run_id', RUN_ID)
          severity     = review.get('severity_breakdown', {})
          val_fails    = review.get('validation_failures', [])
          llm_finds    = review.get('llm_findings', [])
          per_file     = review.get('per_file_results', [])
          total_issues = review.get('total_issues', 0)
          files_rev    = review.get('files_reviewed', len(files))
          tok_in       = review.get('token_usage', {}).get('input_tokens', 0)
          tok_out      = review.get('token_usage', {}).get('output_tokens', 0)
          tok_tot      = review.get('token_usage', {}).get('total_tokens', tok_in + tok_out)
          cost         = review.get('cost_usd', 0)
          model        = review.get('model', '')
          rev_latency  = review.get('latency_ms', elapsed_ms)

          print(f'[review] gate={gate}, issues={total_issues}, '
                f'tokens={tok_tot}, cost=${cost:.6f}, latency={elapsed_ms}ms',
                file=sys.stderr)

          # â”€â”€ build PR comment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          passed = gate == 'pass'
          lines  = [
              f'## {"âœ… AI Code Review â€” PASSED" if passed else "âŒ AI Code Review â€” FAILED"}',
              '',
              f'**Gate:** `{gate.upper()}` | **Issues:** {total_issues} | **Files reviewed:** {files_rev}',
              '',
              '| Severity | Critical | High | Medium | Low | Info |',
              '|----------|:--------:|:----:|:------:|:---:|:----:|',
              f'| Count    | {severity.get("critical",0)} | {severity.get("high",0)} | '
              f'{severity.get("medium",0)} | {severity.get("low",0)} | {severity.get("info",0)} |',
          ]

          if val_fails:
              lines += ['', '### Validation Failures (pattern rules)']
              for v in val_fails[:25]:
                  sev = v.get('severity', '?').upper()
                  cat = v.get('category', '')
                  msg = v.get('message', '')
                  loc = v.get('file', '')
                  ln  = v.get('line_number')
                  if ln:
                      loc = f'{loc}:{ln}'
                  lines.append(f'- **[{sev}]** `{cat}` â€” {msg}')
                  lines.append(f'  ðŸ“ `{loc}`')
                  if v.get('suggestion'):
                      lines.append(f'  > ðŸ’¡ {v["suggestion"]}')
              if len(val_fails) > 25:
                  lines.append(f'- *â€¦and {len(val_fails) - 25} more validation failures*')

          if llm_finds:
              lines += ['', '### AI Findings']
              for f_ in llm_finds[:25]:
                  sev = f_.get('severity', '?').upper()
                  cat = f_.get('category', '')
                  msg = f_.get('message', '')
                  loc = f_.get('file', '')
                  ln  = f_.get('line_number')
                  if ln:
                      loc = f'{loc}:{ln}'
                  lines.append(f'- **[{sev}]** `{cat}` â€” {msg}')
                  lines.append(f'  ðŸ“ `{loc}`')
                  if f_.get('suggestion'):
                      lines.append(f'  > ðŸ’¡ {f_["suggestion"]}')
                  if f_.get('reasoning'):
                      lines.append(f'  > â„¹ï¸ {f_["reasoning"]}')
              if len(llm_finds) > 25:
                  lines.append(f'- *â€¦and {len(llm_finds) - 25} more AI findings*')

          if not val_fails and not llm_finds:
              lines += ['', '*No issues found. Great work! ðŸŽ‰*']

          lines += [
              '',
              f'<sub>Model: `{model}` | Tokens: {tok_tot:,} | Cost: ${cost:.6f} | Run: `{run_id_full}`</sub>',
          ]

          comment_body = '\n'.join(lines)

          # â”€â”€ post PR comment via GitHub API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          try:
              gh_body = json.dumps({'body': comment_body}).encode('utf-8')
              gh_conn = http.client.HTTPSConnection(
                  'api.github.com', 443, timeout=30,
                  context=ssl.create_default_context())
              gh_conn.request(
                  'POST', f'/repos/{REPO}/issues/{PR_NUM}/comments',
                  body=gh_body,
                  headers={
                      'Content-Type':          'application/json',
                      'Content-Length':        str(len(gh_body)),
                      'Authorization':         f'Bearer {GH_TOKEN}',
                      'User-Agent':            'AI-CodeReview-Bot/1.0',
                      'Accept':                'application/vnd.github+json',
                      'X-GitHub-Api-Version':  '2022-11-28',
                      'Connection':            'close',
                  })
              gh_resp = gh_conn.getresponse()
              gh_st   = gh_resp.status
              gh_conn.close()
              if gh_st in (200, 201):
                  print(f'[comment] PR comment posted (HTTP {gh_st})', file=sys.stderr)
              else:
                  print(f'::warning::PR comment returned HTTP {gh_st}', file=sys.stderr)
          except Exception as e:
              print(f'::warning::PR comment failed: {e}', file=sys.stderr)

          # â”€â”€ post to /api/metrics/ingest â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          metrics_pl = {
              'repository':      REPO,
              'project_id':      PROJECT,
              'workflow_run_id': RUN_ID,
              'timestamp':       review.get('timestamp', ''),
              'request_count':   1,
              'input_tokens':    tok_in,
              'output_tokens':   tok_out,
              'total_tokens':    tok_tot,
              'latency_ms':      rev_latency,
              'status':          review.get('status', 'success'),
              'files_reviewed':  files_rev,
              'issues_found':    total_issues,
              'critical_count':  severity.get('critical', 0),
              'high_count':      severity.get('high', 0),
              'model':           model,
              'cost_usd':        cost,
              'pr_number':       PR_NUM,
              'branch':          BRANCH,
              'triggered_by':    ACTOR,
              'source':          'pipeline',
          }
          metric_id = None
          try:
              ms_st, ms_resp = api_post(
                  API_URL, '/api/metrics/ingest', metrics_pl,
                  extra_headers={'x-api-key': API_KEY})
              if ms_st in (200, 201):
                  metric_id = ms_resp.get('id')
                  print(f'[metrics] ingest recorded (id={metric_id})', file=sys.stderr)
              else:
                  print(f'::warning::Metrics ingest HTTP {ms_st}: {ms_resp}', file=sys.stderr)
          except Exception as e:
              print(f'::warning::Metrics ingest failed: {e}', file=sys.stderr)

          # â”€â”€ post to /api/metrics/runs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          run_detail = {
              'run_id':               run_id_full,
              'metric_id':            metric_id,
              'repository':           REPO,
              'pr_number':            PR_NUM,
              'commit_sha':           SHA,
              'actor':                ACTOR,
              'branch':               BRANCH,
              'base_branch':          BASE_BR,
              'workflow_run_id':      RUN_ID,
              'project_id':           PROJECT,
              'gate_status':          gate,
              'status':               review.get('status', 'success'),
              'validation_failures':  val_fails,
              'llm_findings':         llm_finds,
              'per_file_results':     per_file,
              'severity_distribution': severity,
              'total_issues':         total_issues,
              'critical_count':       severity.get('critical', 0),
              'high_count':           severity.get('high', 0),
              'medium_count':         severity.get('medium', 0),
              'low_count':            severity.get('low', 0),
              'files_reviewed':       files_rev,
              'input_tokens':         tok_in,
              'output_tokens':        tok_out,
              'total_tokens':         tok_tot,
              'cost_usd':             cost,
              'model':                model,
              'latency_ms':           rev_latency,
              'timestamp':            review.get('timestamp', ''),
              'runtime_ms':           elapsed_ms,
              'source':               'pipeline',
          }
          try:
              rd_st, rd_resp = api_post(
                  API_URL, '/api/metrics/runs', run_detail,
                  extra_headers={'x-api-key': API_KEY})
              if rd_st in (200, 201):
                  print(f'[runs] run detail stored (run_id={run_id_full})', file=sys.stderr)
              else:
                  print(f'::warning::Run detail HTTP {rd_st}: {rd_resp}', file=sys.stderr)
          except Exception as e:
              print(f'::warning::Run detail store failed: {e}', file=sys.stderr)

          # â”€â”€ write step outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
          with open(GH_OUT, 'a') as gf:
              gf.write(f'gate_status={gate}\n')
              gf.write(f'total_issues={total_issues}\n')
              gf.write(f'critical_count={severity.get("critical", 0)}\n')

          print(f'[done] gate={gate}, issues={total_issues}', file=sys.stderr)
          PYEOF

      # â”€â”€ Step 6: Enforce gate result â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
      - name: AI Code Review Gate
        if: always() && steps.diff.outputs.no_files == 'false'
        run: |
          GATE="${{ steps.review.outputs.gate_status }}"
          ISSUES="${{ steps.review.outputs.total_issues }}"
          CRIT="${{ steps.review.outputs.critical_count }}"

          echo "Gate:     ${GATE:-unknown}"
          echo "Issues:   ${ISSUES:-0}"
          echo "Critical: ${CRIT:-0}"

          if [ "${GATE}" != "pass" ]; then
            echo "::error::AI Code Review gate FAILED (${ISSUES} issue(s), ${CRIT} critical). Fix the reported issues before merging."
            exit 1
          fi
          echo "AI Code Review gate PASSED."
